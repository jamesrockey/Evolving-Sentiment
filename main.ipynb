{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving sentiment in Crypto markets\n",
    "James Rockey (jrockey2)\n",
    "\n",
    "Kareem Benaissa (kareem2)\n",
    "\n",
    "### This project explores the relationship between cryptocurrency sentiment through tweets\n",
    "\n",
    "This is done in the following steps:\n",
    "\n",
    "1. Calculate sentiment of tweets with BERT model pretrained with financial sentiment\n",
    "\n",
    "Model: https://huggingface.co/ProsusAI/finbert\n",
    "\n",
    "Tweets dataset: https://www.kaggle.com/code/codeblogger/bitcoin-sentiment-analysis\n",
    "\n",
    "Tweets are preprocessed before they are fed into the model.\n",
    "\n",
    "The FinBERT model outputs percentage confidence in three following sentiment categories: ['positive', 'negative', 'neutral']\n",
    "\n",
    "2. After sentiment scores are calculated for every tweet, we compare the effect of sentiment on predictive power of LSTMs. \n",
    "\n",
    "For the purposes of this research we want to explore intraday sentiment. So, we collected tweets from 15 random days in February 2021 and March 2021, and for each of these days we calculated sentiment in 10 minute increments. We then considered different sized sequences of 10 minutes to predict the next 1 or 2 sequences. We compare LSTM's prediction of price, volume, and other features, using these features as a baseline, with its performance when sentiment and weighted average sentiment are included in trainging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Calculating Sentiment\n",
    "\n",
    "In our dataset, the 'text' column contains the content of the tweet. We preprocess this text and use our BERT model to calculate sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48583 entries, 0 to 48582\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   user_name         48582 non-null  object\n",
      " 1   user_location     28273 non-null  object\n",
      " 2   user_description  45263 non-null  object\n",
      " 3   user_created      48583 non-null  object\n",
      " 4   user_followers    48583 non-null  int64 \n",
      " 5   user_friends      48583 non-null  int64 \n",
      " 6   user_favourites   48583 non-null  int64 \n",
      " 7   user_verified     48583 non-null  bool  \n",
      " 8   date              48583 non-null  object\n",
      " 9   text              48583 non-null  object\n",
      " 10  hashtags          38416 non-null  object\n",
      " 11  source            47685 non-null  object\n",
      " 12  is_retweet        48583 non-null  bool  \n",
      "dtypes: bool(2), int64(3), object(8)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/Bitcoin_tweets.csv', sep=',', header=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "MODEL = \"ProsusAI/finbert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def get_labels(): \n",
    "    labels=[]\n",
    "\n",
    "    # This is for another BERT model that we tried:\n",
    "    # mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "    # with urllib.request.urlopen(mapping_link) as f:\n",
    "    #     html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    #     csvreader = csv.reader(html, delimiter='\\t')\n",
    "    # labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "    # This is for the FinBERT model:\n",
    "    labels = ['positive', 'negative', 'neutral']\n",
    "    return labels\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    '''\n",
    "    Preprocess text (username and link placeholders)\n",
    "    '''    \n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "\n",
    "def process_tweet(text: str):\n",
    "    '''\n",
    "    Calculates sentiment scores for the given text\n",
    "    '''\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    return scores\n",
    "\n",
    "# Modified print_scores function to return values instead of printing\n",
    "def get_sentiment_scores(scores):\n",
    "    labels = get_labels()\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    return {labels[ranking[i]]: np.round(float(scores[ranking[i]]), 4) for i in range(scores.shape[0])}\n",
    "\n",
    "# Function to apply to each row\n",
    "def analyze_sentiment(row):\n",
    "    '''\n",
    "    Takes in row from dataframe and returns a series of sentiment scores\n",
    "    Used in df.apply()\n",
    "    '''\n",
    "    text = row['text']\n",
    "    scores = process_tweet(text)\n",
    "    labels = get_labels()\n",
    "    sentiment_scores = get_sentiment_scores(scores, labels)\n",
    "    print(pd.Series([sentiment_scores.get('positive', 0), \n",
    "                      sentiment_scores.get('neutral', 0), \n",
    "                      sentiment_scores.get('negative', 0)]))\n",
    "    return pd.Series([sentiment_scores.get('positive', 0), \n",
    "                      sentiment_scores.get('neutral', 0), \n",
    "                      sentiment_scores.get('negative', 0)])\n",
    "\n",
    "def print_scores(scores, labels):\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    for i in range(scores.shape[0]):\n",
    "        l = labels[ranking[i]]\n",
    "        s = scores[ranking[i]]\n",
    "        print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example use of sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) positive 0.9032\n",
      "2) neutral 0.0864\n",
      "3) negative 0.0103\n"
     ]
    }
   ],
   "source": [
    "text = '''I'm absolutely ecstatic about Bitcoin's remarkable \n",
    "performance and incredibly optimistic about its\n",
    " potential to revolutionize finance''' # example tweet\n",
    "\n",
    "scores = process_tweet(text)\n",
    "labels = get_labels()\n",
    "print_scores(scores, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to dataset\n",
    "Note, this may take several hours. Data with sentiment scores already calculated is found in this file: sentiment_added_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['positive', 'neutral', 'negative']] = df.apply(analyze_sentiment, axis=1)\n",
    "# df.to_csv('sentiment_added_data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Analyzing Sentiment\n",
    "\n",
    "Here, we explore how sentiment using the bert model effects LSTM prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate 10 minute sentiment scores for each day in dataset\n",
    "\n",
    "The sentiment score for a given day is found by taking an average of the ['positive', 'negative', 'neutral'] columns in our dataset during a 10-mintue interval. \n",
    "\n",
    "For each trading day, we group tweets into 10-minute intervals starting at 12:00:00 am until 11:59:59 pm. \n",
    "\n",
    "We also explore how the \"reach\" of a tweet affects daily sentiment by calculating a weighted average over the number of followers twitter user.\n",
    "\n",
    "If a 10-minute slice is missing tweets, we give each column equal weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following functions calculate the weighted average \n",
    "and average sentiment scores for a group from the dataframe.\n",
    "\n",
    "group is from the df.groupby() function\n",
    "\n",
    "Input: group from dataframe\n",
    "\n",
    "Output: series of weighted average and average sentiment scores\n",
    "\n",
    "'''\n",
    "\n",
    "def weighted_average(group):\n",
    "    weighted_positive = (group['positive'] * group['user_followers']).sum()\n",
    "    weighted_neutral = (group['neutral'] * group['user_followers']).sum()\n",
    "    weighted_negative = (group['negative'] * group['user_followers']).sum()\n",
    "    total_followers = np.sum(group['user_followers'])\n",
    "    \n",
    "    if total_followers == 0:\n",
    "        return pd.Series({\n",
    "            'weighted_avg_positive': 1/3,\n",
    "            'weighted_avg_neutral': 1/3,\n",
    "            'weighted_avg_negative': 1/3\n",
    "        })\n",
    "    return pd.Series({\n",
    "        'weighted_avg_positive': weighted_positive / total_followers,\n",
    "        'weighted_avg_neutral': weighted_neutral / total_followers,\n",
    "        'weighted_avg_negative': weighted_negative / total_followers\n",
    "    })\n",
    "\n",
    "def average(group):\n",
    "    avg_positive = group['positive'].mean()\n",
    "    avg_neutral = group['neutral'].mean()\n",
    "    avg_negative = group['negative'].mean()\n",
    "\n",
    "    total_followers = np.sum(group['user_followers'])\n",
    "    \n",
    "    if total_followers == 0:\n",
    "        # print('INVALID TOTAL' + str(count))\n",
    "        return pd.Series({\n",
    "            'weighted_avg_positive': 1/3,\n",
    "            'weighted_avg_neutral': 1/3,\n",
    "            'weighted_avg_negative': 1/3\n",
    "        })\n",
    "    return pd.Series({\n",
    "        'avg_positive': avg_positive,\n",
    "        'avg_neutral': avg_neutral,\n",
    "        'avg_negative': avg_negative\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
